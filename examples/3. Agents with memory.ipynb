{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0bd25c",
   "metadata": {},
   "source": [
    "Agents can perform all sort of actions, as many as software enables we can think of. But one critical ability we might like to provide is the ability to search for extra knowledge.\n",
    "\n",
    "LLMs have a knowledge cutoff as they are trained at a specific point in time. Having the ability to look for information and fact in order to respond to a question it is critical for trusting the agent, as it can return the sources its reasoning is based on and decrease the amount of hallucinations by grounding ins thinking process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720a080b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be6a81",
   "metadata": {},
   "source": [
    "Create the brain of our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9063125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759249012.652934 1239565 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331e198",
   "metadata": {},
   "source": [
    "Create the tools of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b6e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8faac429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this ipynb we set parallel tool calling to false as math generally is done sequentially, and this time we have 3 tools that can do math\n",
    "# the OpenAI model specifically defaults to parallel tool calling for efficiency, see https://python.langchain.com/docs/how_to/tool_calling_parallel/\n",
    "# play around with it and see how the model behaves with math equations!\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db25bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# How to chain the inputs\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719ccfb",
   "metadata": {},
   "source": [
    "We create a graph with `Assistant` and `Tools` nodes.\n",
    "\n",
    "We add `tools_condition` edge, which routes to `End` or to `Tools` based on  whether the `Assistant` calls a tool.\n",
    "\n",
    "Now, we add one new step:\n",
    "\n",
    "We connect the `Tools` node *back* to the `Assistant`, forming a loop.\n",
    "\n",
    "* After the `assistant` node executes, `tools_condition` checks if the model's output is a tool call.\n",
    "* If it is a tool call, the flow is directed to the `tools` node.\n",
    "* The `tools` node connects back to `assistant`.\n",
    "* This loop continues as long as the model decides to call tools.\n",
    "* If the model response is not a tool call, the flow is directed to END, terminating the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e3ef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAQAElEQVR4nOydB3wUxdvHZ/dK2qVX0hsh9IChKSglCApSbGAISG+KSHtRuoCKoBT/ChiQXiWCAUSqgAiCFIGEEgiEJKSS3nNl933uNjku5C4kwG3msvP9JPe5m5ktN/u7Kc/MPCNmWRYRCPWNGBEIGECESMACIkQCFhAhErCACJGABUSIBCwgQnySR8mKmH/ycjMUSjmjkKtU8qrRFPyziKIQoxOisYBRNLxhWJaGN+zjWBaxFCViWRVV9Tyak8CRDFUlkKVoMcUoK2xq6s9cKKQWIVZVeSGkcwmEzKxEIhEyk4k9/M1f6mGHTBCK2BE5Uu6Un/w1syBHrlYVhcwtRWaWIopileWMbjKKUssCgRRU2iCtEDVRjOYNw+rGUmI4UdV8pjUxoEWVTjgN+mZpCcUoKoWokSFFsywDQqRYTWJ9QhSrfzblTHkJo1SyEnPaPcCi70g3ZDoQIaKMRPn+dSmKMsbWSdr6FdsWXWyQScOgU1FZ928UlZWoXL0s3vnEHZkCQhfinhUpGcml3sGyfmNNqfyoDdnpykM/pxQXKLu+6xrcTobwRtBCXD8nQSKmP1zggxouN84XntmX6dnYsu/oRghjhCvE9bPvewXJen3oggTA+jkP2vW0b/2aLcIVgQpx7cx7ga1twsKdkWBYNyfBxdO8/3hMy0UaCY8N8x94N7ESlAqBMYv9MpPL/t6XjbBEcELcH5lO0+hNkzJtvCjGLPS7eiYXYYnAhKhCyXFFw+f7ImEiQl6NLTfMS0D4ISwhbv4y0dHdHAmY/hPcS0uZO1eKEWYIS4iFeYrBn3oiYePua37mt0yEGQIS4oHINEuZGKonPvnss8+io6NR3enZs2dKSgoyAn3GeJQWqRBmCEiI6Qll3sFWiF9u3ryJ6k5aWlpurrF6FVIpkprTJ3Y+QjghICHK5UxoDwdkHM6ePTtu3LjOnTsPGDBg/vz5WVlZEBgaGpqamrpo0aKuXbtyyTZt2gTJunTpAslWrFhRVlbGhYeFhe3evXv58uVwhtOnT7/11lsQ2L9//2nTpiEj4ORmnp5UhnBCKEK8d70ErDZ2rkapmG/fvj158uR27dpFRUVBXZycnLxgwQKkUSe8zp0799SpU/Dm8OHDa9euBXV+/fXXERERR48ejYyM5M4gkUj27dtXWlr63XffvfLKKytXroRAqNPhIzICzl5muNXOQpmPmJ5QKpYY61d39epVMzOzESNGiEQiNze34ODg+Pj46smgXNyxY4e/vz/3MSkp6dy5c5988gn3USwWz549G/GCq7f5jX/yEU4IRYglRSrKaN0UKOQUCsWoUaN69eoF5WJgYCCEVE8GFfGePXsuXrz48OFDpVIJIQ4Oj5sKLVq0QHxh7yRRMXiViEKpmhmGYRkGGQdQ3vbt2xs3brxq1arBgwdD+y8mJqZ6sq+++urkyZNTpkw5cuTIpUuXhg8frhtrbW2NeEMsojB79EIRopW1pGJms3EAFULF+ueffy5btszGxmbq1Knl5eVPpIEm43vvvQdNQFtb9SyY9PR0VE/kZZYhCmGFUITo5C6VlxqrMrpy5Qq09uCNpaVlt27doOMCxpdHj6rYR6DuBmlyEgTy8vL++usvVE9kJJZTNF5KFIoQg9tbsyySlxhlzhsIccaMGXv37gX9QaW8fv16Hx8fT09P6MG4uLicP38eKmKKonx9fQ8cOAB96suXL0OR+frrrxcUFBQX6xltg5TweuzYsdjYWGQEMpPLLK35tew/DQHZESVS+sKRHGQEoL88cODApUuXwnDIrFmzPDw8Vq9ezUWNHDkSeifTp08H0wy0Ec3NzYcMGbJx40bo2YwZMwb61z169ABb4xMnBBGDKRFsPT/88AMyAnlZchcPvMbcBTQx9pflD4vzFSO+8EOC539T4kcvCrCQYVQ7C6hEDAt3KSpQIsHz+89pUjMKKxUiQS2wd3CTWsrE0WtT+4/Xv8JSpVJBRak3Si6Xw+AHRel5eGCg3rBhAzIOmzTojZLJZEVFRXqjmjdv/uOPPyIDJMWVtO1qjzBDWGtWHsaVR0cmf/RdoKEE1ZtrHPDI4cHrjYIREeiRIONQqEFvFJjHocWpNwp+M87O+hdCHN2emRBTOG5JAMIMwS2e2rXsIdi2w2d6IUGyenr8wIk+jfwlCDMEt2Zl8AzPwlz5hT8wXbphVDYueOARaIWhCpEwV/FBxXTpRE5hhrCqgh1LH4qlNLbLSYW7wH719Hthg92CQvmeKlsvbFmU5OAu6TsKX2cPgnY5snraPXd/iwEfmYabomdmw7wEcysx5s1ioTth2jD/gULOtH/dsU03fN1xPDN7V6em3Stp3Mbm9QjcPasQt3To3IGca2dyEYV8m8leH+IqMn3T6r1rJZdP5GSllFvaiofP9kF4jSrrhwixglNRj+KvFZUVq0RiysJKJLOXWFpJaLFKIdfJHwrRFKX2wclW8a6pzkQW0TTFaPxzVjjz1CShaVQxDZKzhT8RqON1U3s4F0ghTRoaIZ1ZlLRI7Yy2+rxKsYRilXRxgaKkSAVfAc5j6yR9baCzR5DJLOImQnySc/uzkuPLSotUSjk8c1ZV1dNrFbfEFUEat64aT8RcXmqEWTEGow1EnCdazRRdWj0F63ECpBG2Tkr1GTSP5sl7o2n1mauHi6VgVxfBwJ2Nk6RJW+ugl3D3hlgdIkS+mTRpUnh4eKdOnRBBB+LMnW+USiWMCiJCVUiO8A0Rol5IjvANEaJeSI7wjUKhkEhwHO2tX4gQ+YaUiHohOcI3RIh6ITnCN0SIeiE5wjcgRNJGrA4RIt+QElEvJEf4hghRLyRH+IYIUS8kR/iGCFEvJEf4BgzaRIjVITnCKyyrnk6o3m6eUBUiRF4h9bIhSKbwChGiIUim8AqZ8WAIIkReISWiIUim8AoRoiFIpvAKEaIhSKbwChGiIUim8ArprBiCCJFXSIloCJIpfGPIl6vAIULkFRjcq8cNp3CGCJFXoF7mtoMkPAERIq8QIRqCCJFXiBANQYTIK0SIhiBC5BUiREMQIfIKEaIhiBB5hQjREESIvEKEaAgiRF4BIapUKkSohhB3nqpfYHCFaLE6RIh8Q2pnvRAh8g0Rol5IG5FviBD1QoTIN0SIeiFC5BsiRL0QIfINEaJeyM5TPBESEkLTFV1DyHNas5tZ3759Fy5ciAik18wbrVq1QurN9NSAKZGiqEaNGkVERCCCBiJEnhg2bJiVlZVuSOvWrYOCghBBAxEiT4SFhenKztHR8YMPPkCESogQ+WP48OE2Njbc++Dg4JYtWyJCJUSI/NGlS5cmTZrAG1tb2yFDhiCCDoLrNceeLUp7UFxWop52oN2rG7qz0HtQqdQfRBJapWC4/eShU8EFIhFFs4jbYZ4WUYwmENKouB3CK7NQLKWV8sf7ioullFL+OHtpMcrNyY2JuSGzkkEnWp1ATCmrbkwuFlFKlc4hmr3uaTHFKCuuqN3lHlXdxZxLWfGeQozuWamKOxSLROZWorZdnWxdEW4ISIgp8fLfN6TAIxKb0eUlVbehpzUPTzMnhhKxrIqqeMbaR0prniZ3kFqSavlBGkYtREorRJEEqRSPzyqSUCqFjm5EakGoVAyIntLsYC8SI1VVkyItqriNikM0t0GLWUZJcbeBKm+coVgaTsNUSan9Okj3+1UKEX5CcEvKMsbSTjJsthfCCaEIMS1BHr3mYUh3x+adbJHgORiZpiiXD5vjg7BBGEJUoTWf34uYHYAIlRzemFpWrBg6GxctCqKzEvV9iq2jOSLo0HuEe3GBKv2BHOGBIISYl6Nw8yZCfBKpGR1zNh/hgSAmPSjKVIg4JayGkmGLC3EpEQUhRBXDMmSZSDUY6NFjkytkGhgBC4gQhQwLVhOEB4IQIqX+oxDhScAUj0u2CEKIrPqPzP99EvXwDjY/T6GUiITqwFAGPqMZwmgjUgij3z42wPC0ejAdD4RRNbMIo98+NqgnSTCks0Ig6CCUNiJNqma8EUrVTGrm6tAiColIG5FH1DOxifmmGup55ipcskUQs2/qMbPv34/v1iP0+vX/EKFGBCHEehxZsbOzHzZ0tIuLWw1pEhLuDQ7vi56Pge/0TE1LQSYLGVkxLg4OjiOGj685Tdydm+j5SE9Py8vLRaYMMd/oB6rUHTs33o2Py8xMbxrcYujQ0W1CQrmo8xfO7t695XbcDQcHpxYtWo8dPcnR0clQOJxn1JjBq1asa9WqTWFR4cZNay+c/zs3L6dJULOwsDf6vDkAQrZsXQ+HQw0+ccKU994dYujSv0Xv2bJ13bw5X/+w+tuUlGR3d88PBg8P69H7v6uXpk5Ta31IRH8ofZ+qey0isXp9IMIDYaxrZutWNSsUikVfzsrOzho8aNjszxe7uLrNnjMlJycbou7cvf35rMlt2rTbtCHq08mfgSC+WbqghnBdli794uaN659++jmkeemlDitXLblx4zroBq7i6up28sQlUGENlxaLxUVFhZu3RE79dNauHQfbtmkPl4AokOnXX66EBNu3RddehYBKiRglMWjzCEXVbbxZIpF8/eUqc3NzaOHBR5DXkSMHY2KvvvZqj9iYq2ZmZkPCR4hEIlBPUOPg+wnxkMZQuC7Xrl95/72IdqEd4X3EkJHt2nWytbGr/aWR5hcSHj6iWTO1i4h33wmP+nXHnTu3OnbsjEwfwYw115F79+7s3bfr3v27+fl5XAjXCAsJCQU1TJo8qke3XqASf/9Art40FK4LSPCXPdvS01M7dewCaZoENa3TpTmaNa1wVGJtrfZeok1j6gjG5UhdLNpQz86dP93b23fl8sjjRy8cO3JeGwUKi1y7PcC/8drIVdD4ixg64ObNmBrCdfm/GfPHjpkExducedP6Dej27XeL63RpDih3UUNEGHbEOvaZL1++AM/7o4nTfH391XvOZ6TpxgYENJ42dXb0vj8XfrEMiqXZc6eWl5fXEK4Fztm3z8DNG6PWR+6EJuCRowf3RG2v06VfLOoWC03aiDxS4R+k1kCfwNLSCjoH3Mc//ojWRl27dqWsvKxD+5ctLS27dO5mLbOZMm1cVvajrEeZesO1BxYUFhw//sebb/SH9h9IFv6gyISuce0v/cJRVxIM6TXzTF2qZn//xtAb3X/g16ysRzt3bYYusL29AxhTkKbDMX/BjAMH90K7DZS0ddt6Ly8fD3dPQ+Hac4po0cZNa+Z/8X+xsdcgDaS8HvNf+3YvQ5Snpzd0k//++1RycmINl64BL29feD116lhS0gNkmogWLFiAGjoXj+Q4eZl7BlrVMr2/XyDDqKBPevzEYSdH54kTpkJ1uWv35szMjDGjP84vyAN7HqjkypV/g4Kazpg+z8pKBoZDveG5uTn7D0S90bufl5d361Ztjx77HRJE798DpsRRIyf2DHsDLufo4BQXd3PHrk12dg4DB7xv6NJglfznnzNgKeR8cUPfCMyNnV/pGhgYZGNtKWi3uAAAEABJREFUk5GRBl0cKEq5XnltiDmTK7MVB7e3QRggCN83P0yLh+zu0NsFEXTY/tV9N2+zAR95IAwQih2RIvMRq0HjNLIilCE+IsPqMGRkhW9YxCAC1ghl9g2Zoo05ghAirfZETNzWY41ASkSMnLzgA/w6KWx+nsJoIzKkjagHtTGBCJFP1J6GSBuxGoxK3XHGBIGMNbPE5QjmCGQ+IpGhHkjVzDcMSwyJelDPjsMmWwRivqHJ0ArmCMTlCEs8PWCOIIQolVJSKdnf4kmk5rSZFS4CEIYQLST5GbhsKIIPKiXr4CxFeCCIgS+/5pbpD0sRQYeMRLlSyXboY4/wQBBCfO0dJ4mUjl79EBEqObE9peXLDggbBLRfc9SKhwV5Kq/G1k4eUpU+uwXLLWzTlx/qXZkrw7VJuDe6R1SEsNV2jdBJxL3VnrDyJCxb2bHndiLnzkBpNl7WPRl3cqryhivSV+6Azl29wq+F+tlSVW6YRqpyKvlO8aOUkn7jPNz9MFqZKqwd7I9uy0y+U6KUM/LyCiFWPqQKEVZ/eKjSD7w2n7T73usRYqVAdEPYqtp8IqTyJAyrqZ20YtReglMWy1YcyOlQs004WxFfMYBJ6dyMRquVJ9Fubg9voGawsJZAFeHdxALhhLCEqJcVK1bA65QpUxAvTJ48edCgQS+//DIyAr/88gt8HYlEYmVl5ezs7OvrGxIS0lQDwhtBCzEmJqZly5Y3btxo3rw54otFixb169evdevWyDiAyu/evUvTNKMpBmF009bW1traOjraiEuknx+BTheFn9/EiRPT09XrhflUITB37lzjqRDo06ePubl6c2paAwixoKAgOTkZ4Y0QS8Ts7Gx4PPHx8e3bt0e8A+q3t7c3ngub0tLSoUOHPnjwQBtiaWn5119/IbwRVolYXl4+btw4eFQODg71okJg5syZ8BtARsPCwqJnz57a+UZQQS9evBhhj7CE+Pvvv48dO9bT0xPVH66urlBEIWPy9ttvu7mpvXaDCq9cufLbb7+tWbMG4Y0ghJifnz99+nSkeUIvvfQSqleWLl3q5+eHjAn0l7t27Qpv3N3d4XX58uVSqXTSpEkIYwQhxIULF44aNQrhQUpKilJp9Bn606ZNg5bowYMHuY/w9cPDw7t37/7wIabDSw25swLdglOnTg0ePBjhBNhu1q5dy5VVPAPd52HDhk2YMKFXr14IMxpsiVhSUjJ69OhXX30VYQa03qA/geoDGxsbaC9CD5qz4WNFAywR09LSCgsLPTw8YHQBEfSxY8eOP//8c/369QgbGlqJeOvWLa5fjK0Kk5KSuDGPegTai9B36dSp0507dxAeNBwhpqamIo2l8MCBA8a2jzwPERERZWVlqL6B0R2ooxcsWACVNcKABiJEEN/8+fORepuJEIQ30E0BYwrCAIlEAnV0bGzsl19+ieobk28j5uXl2dnZ7d27F2yEiPBM7Nu3LyoqasuWLSKRCNUTpi3EdevWQd6NHDkSmQ6JiYk+Pj4IM+Li4j788MOffvrJqBMyasBUq2ZoC2ZnZ0Or37RUCK3DIUOGIPxo0qTJ+fPnv//++507d6L6wCSFGBkZCX1PqJHHjRuHTAqof/z9/RGu/Pzzz9DnmzNnDuId0xPioUOH4LVx48b12KB5ZsCUDU0xhDEwNti5c2docIMtFvGIKbUR4RHCCFV+fr6trS0yTVQqFdjb63f6T22ACgeajEuWLOnQoQPiBZMpEWfOnMlNPDZdFQKPHj0aP74OWyrXF97e3idPnoRf/oYNGxAvmIAQz549C69Tp059//33kYlDURSGXWZD/Pjjj9AphMoaGR+shahUKvv168fNqnd1dUWmD3wLeLrIdJgwYQI8gt69e2dmZiJjgm8bMT09HUYgwN5RLzOmjIRcLs/KyjK5bwT3DK3zb775pmXLlsg4YFoiwtBTTEyMg4NDQ1Ih0qxsgqFIkxtEcHJyAmMFWBkzMjKQccBUiFAcQu8YNTigp7V69WoYGa/3CTjPwNWrV43XQCKeHuqH5ORkmqY9PLDYGbQ23L17d968ecYbd8G0RFRpQA0XLy+viRMnFhcXIxMBhAiDCMhoYCpEqL+2b9+OGjTR0dFxcXFFRUXIFLh3715gYCAyGpgK0XiOELCibdu2KSkp586dQ9gDJaJRhYip6+KxY8ciYdCkSZNPPvmkVatWMpkMYUx8fLwQS8QG30bUBcwiBQUF2K44RhoPBTDE4uLigowGpkKEUc61a9ciwQDm0tzc3PqaC/hUjF0cIpzbiELbtgwGLVJTU8HijfCDByESOyJelJSU3L59GzoxCCcWL17cokWLAQMGIKNB2oh4YWlpaW5u/tVXXyGcgBLRqEZEhK0Q9+3bt2zZMiRImjVrFhwcjHBCuG1EqVQq5K1tuaWx+/fvRxgAo5HOzs7GtuxiKsR+/frNnDkTCRvovnBuHesXYw/ucWAqRIZheHAiiDl+fn7Dhw9H9Q0P9TLCVojHjh3jXIgIHOirosqdYOoLQQtRIpHQtEC33qgOlIv1uOSKn6qZ2BFNg8LCQmtra2iuiMXq6QG9e/eG3+qBAweQkYGRve7du3Pr14wKaSOaBqBCpFn9Xlxc3Ldv36ysLBgSPHLkCDIyPFgQOTAV4vnz5/lZxWharFq16o033uA2zILBwBMnTiAjY+zZX1rwbSMK2Y5oiEGDBsEYIPce8icuLo4TpfHgp6eCsBViu3btVq5ciQg6hIeH37t3TzckIyPj9OnTyJjw01NB2AoRulAKhQIRdIB2s6enp67rKblcDnYuZEyMvUJAC6YztGNiYqBE5M3xikmwa9euK1euXLx48cKFC0VFRWlpaa5WbdkCh2N77zRq5Mal0W5qXjd0Nz/XAbrqvk6vJd+kklFBzSkNQdOUi6eZk8fTXTXjZb4ZPXo0ZDHcErxCr9DFxQWKAWgVHT9+HBF02PjF/ZICFUUjldq08LgxXV0nXFzNz5g7qjYaq31KDrEEBEZJpFSrV+w7vGlXU0qEE82aNdu2bZvWlM3NnocRd0TQIfLz+05eFu9ObISw8An/dG6cy485m9PI18y7mcGdjvBqI0ZERFT3HVhf+9niSeSs+01DHXsOMRkVAs1fth00w+/Q5rRLRw1678BLiFAX9+nTRzfE0dERT6fT9cIfmzPFElFImEl6iGzawe7q6WxDsdj1mj/44APdQjEkJCQoKAgRNGQklTk1MkemSdseDgoFKzfgTwA7IdrY2Lz11lvciKqDg8PQoUMRoRJFuVJsbsJzQRgGZWXoXx2G47fSFootNCBCJUo5q5SbsHmVVbGMgZVIz9Vrlpeic79nZSaWFRUoGJZSKeAyOv16TS9fa9miaIplWG2UOryqZzbdBF19vlZ6KqUiyeqZ96lqBgn1KdkqA4Dqs6HHNjSI1D0KileKpsUiZOUg8Qy06NTHARHqAxYZNPw8oxAPb85IiiuRl6lEEpFITNMSsdhcJJKAEKpdp1KJVWytlOYTqzdh5ceKW2d17WTao6sd/MQ3rHKUWCyCSkElV+ZkKDKSSi8dz7GyEQe1te7c3xGZGk/8Ak0PA3VwnYX4+4aMxJtFtIiydrEJamaPTBCVnEm5mXP9TF7s2fyQrrYd3zQlOVKUCc8fVRcXL6RE/OmzBDiRd8tGMhcT9tYlktLeIU4IOT26X3D5RPbN80UjF5qMp3+TRl1PGRBibTsrSbdLf5gab+NiFdzV26RVqIuzv03zMD9KJF494z4iGB+q4l8PtRJibqZif2RKs+5+jZqaXqPqqfi1d3Nt7Pzj9HuIYGTULXsDbdynC/H+9dKdy5Jb9PSjTW/ru9ri6GXpH+qNvxZZZNorjNR9VFr/N3i6EP/YnNq4gxdq6FjY0k4+9pGzEhDGaKxeJoxagwZ2U3iKEH+alWDtbCWxEsTKTtdAW0pE71iajHCFok1biZo2Yt2r5pN7slQKxru1gGZhNX7ZMye9PP2BHGEJDAGYdN3MGp7KWJMQb/yT5+xnkpbC58HS3nz/T7h6EaaQSReJlOEJtQaFeG5/Noy5OfthOuPoaszx6XM7FBXnoheNf2gjeRmT/whL74ws4r9IHPB22Jat69ELwtDdGxTirUuFVnYG59M2bMRmoiPb0lCD4IuFnx36Ixphg6Hy3KAQSwqVrgGCq5c5rF1k2WnlqEEQF3cTYUWdhvhuXSimaWRhZ6zZ6Ll56Xuiv0pKjqVFYh+vFoMGzpVZqUV/9kLUsVM/R7y/OPrQiuzsZEcHz25dhrVt3Ys76uDh/126dshMatmmVS8XJyMOyrkF2OYkN4QtKbv1CIXXZd8uWrN2xYHoU0i9C/vpzVsiE5MSbG3tWrdqO2H8FAeHikGKGqI4wBz9696dR44cTH6Y6OPtFxraceSICbrLW2tFnUZWEm4WqmdNGQe5vOx/kaOUCvnUj7ZPHLVWqZSv2TCR261TJBKXlhYeO7n+3X4zZ02LbhzQbvfehQWF6vnl5/799dTZbX1e//jTCZutZQ5/HF+DjIZIKqJFVNxF7DYno/TNRaqBw4fUzpNmTJ/LqfDipfNz5k3r2rVn1J4jC+YvjYm9+vmsyVzKGqK07N27a9v2De++E75rx8G3Bw4+euz3Xbu3oLpQwzQw/UIsylWJxcbqnYGkiovzhry/yMG+kZuL/3v9Z2Vk3o+9eYqLVakU3V8d7uPVUmZl16XTYBWjfJh6G8LP/LO7WXCXdm36WJjLXunwrqe7cb1Mi0R0dip+tTNFoeeYfbNh45o2IaHhHwy3llk3a9pi3NjJd+7evnX7Rs1RWq5dvxLUOLhXr752dvbwunLFug7tX0F1pU4lolKpUhtPjcOD5OveXi1sbSrMkw727lAFJ6fe0ibw8ayYlW1pYQOvxSV5UCnk5KZ4ezTTpvH3bYOMCQymFRZi545M3WN+jk5zQkJ869YvaT+2aqnOw6TEhJqjtEBdfOnyhQVfzITaOTs7y8PdMzCwbsuJaijb9LcRKYo13r7WBQVZSQ9jwfhSNfCR9r1E8uTsnrLyYpVKaWZmpQ3hNGpEKAoKRYQZ6gIRPSMlJSXl5eUymbU2xMZGbZvLzcupIUr3DP3eesfF2TX6QNSSpQvgI5Sg8+d/Y2tTBwMfY/hXpF+IEqmEQsYqD2Qye1+vVr3DqrhAtbKq6fuYm1lB87G8/PHuxiWlBcioMMjCEjsh6psBX1u4HVyKigq1IQUF6g6ZvZ1DDVFPnKRjx87wl5OTfebvk1u2rlv27cLFC79DtYY2PA9MvxDtnMTGs180cg28HnsiwK+t1vFceuZ9Z0fvGg6BlHa2bkkpjy0R9x/8h4wJyzCuvpYIN2qY0FcLfH0DYmOvaj/+d/USvAYEBNUcpQVq5KCgpn5+AdCb7t/v3dzcnMNH6rYBB6t9qYb+H31AK5lSYazK+bWXw+WKsqjor7OyH2Y+Sjx45IfVP4/Py8+o+ajWLcJu3j5z6NiaouI86O4kJnvdo1gAAATKSURBVMcgoyEvUrEMG9gaR3s+VZcy0czMzNnZ5dKl8yAspVIJ1pbLV/79Zc+2gsKC/Qd+XfX9krZt2nHtvBqitEA3ee786efO/QVp/vnnDKgw9KWOqK7UyY7o1xIKA7Ywq9za6cVPxra0tJn+8Y6TZ7b+vHVKubzUz6fVqIjljg4eNR8V9tqI4uLcf6/s//OvTX4+IX17fbIjah5n9HnhZCTkwuAKwpC6V81Dwkdu3LT24sV/duw40C6047qfduzcvXnr1vVWMtlrr4aNGf0xl6yGKC2zZy1e9t2i2XOngu3Qx8evd69+Hwz+ENWFGmbfGPQGtnlRoooR+7d3Q8Ij7nSyq4/ZgAmNEGas+b97HoEW3Qa5I9Nk04L4geM9PJvoqWoMtsdbdbYrLcBxy1YeUCiUGKqwAVDD5CGDq/jadLM9fygr7XZuo2D9I87Qqvv2h3C9URZmstJy/cMSbs7+H49dh14cc77sYSgKLD7Q164e7uvdavRQg1voxF9IldlIEJZQJj5Fm3225aTtejleOJxtSIjWMsepE7fqjYJBPKlUv68gmn7BHhkN3YP6NhTlUomeNq5YVNMYenmhfNSSAIQrjClPjFVPi32GBfahYXYxZ/MTLqX5heqpp6CwgUERVN+82Hu483eyR6AlhWmBqC5OTH3NCvVsa1ZGzPcpLSzPSy1BAiAl9hFNsaR1WC88ffBg4pKAlJuZqKGTfjOnIKtk9GI/hDMUMuntZ55vgT2Nxi8NiDmWkJNSjBooydez8rOKJnzjjzCHRSa9dyL7DGtWdBGJ0KTlgam3MhMuGnefo3rhzt8Pi3OLx32Nd1moQV0amvZyUop9Tt83wMffBVKs8tbJxPS4PNQgSLz2KPZYgq2daPwS7MtCDc85DazeqWFab92MKcPn+/x7JO/q6dyclDwLGwvnAHuZvek4t68kN6Uo+0F+eanczFL89gQv98Ym41PqeaaB4UANbcQ6W/Xa97KDv0vH826cz39wOYXSIBLRIinNQPuF0V7ysamh0imn9hbYyltSJ6/IW0qPex6aUpvNuNZ5hdtZ7rxU5cGaZoe6BU/DpSmdBBUuZblPtIhlVRTDsCqFCo6CWGsHadggD9+WJrZM8XmmgeHAi/cYCyZG+IM38VeL714tzM9SMAySlzJaIdIiSuvGmKYRPH2tKZYSqX0pI040le1XbaCuV2NKDG0BFg4HKyirmR4J5nBGqZ48TldsusQpmAtnNQlYRkk9/qi5DbEEfiuUuYXYzsWyaQdbj4AG4lavIfG84xyBIVbwhwiE5wPTTSEJepFIRWKJCXsHVK/IM+DdkAjRlJCYU+UlxltNZHSgve7pr793Kwh/cw0G36bW2emm6oLi3P4sMwsRMlCgEyGaEq+94wAP7M8dJjnimnijoPt7LoZi8dqvmVAbtixOAsNB225OPs1NYF++ojz2yvFHibcLP5zja2VrsIFLhGiS7FmZkpNWrlKxKhXWjw/MZ2AMtpCJXx/i6h5Y08+GCNGUkaPS0qp+HLUeWbWmf5atEvV4Szod2zJd6dq6SiCNuLVplYewNEUxuuMKqHLEoPKjdtRCeyGRyEKGagMRIgELiPmGgAVEiAQsIEIkYAERIgELiBAJWECESMCC/wcAAP//I6cPsAAAAAZJREFUAwDn1or/mKDEIQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa4c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"Add 3 and 4. Multiply the output by 2. Divide the output by 5\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9aeea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Multiply the output by 2. Divide the output by 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (53e86d4c-9089-49b9-b5c9-275b8cdc8d54)\n",
      " Call ID: 53e86d4c-9089-49b9-b5c9-275b8cdc8d54\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (830c9eb9-58d1-4458-8cf8-51d56b175881)\n",
      " Call ID: 830c9eb9-58d1-4458-8cf8-51d56b175881\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (ab8beda9-1673-4a25-88f3-d90e171e1ba9)\n",
      " Call ID: ab8beda9-1673-4a25-88f3-d90e171e1ba9\n",
      "  Args:\n",
      "    a: 14\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "2.8\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The final result is 2.8.\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf1fd71",
   "metadata": {},
   "source": [
    "We could add the ability to perform web searches to the agent so that a more general approach is provided to potentially add any type of information.\n",
    "\n",
    "A critical point in this is to remember our previous conversations when we continue interacting with the agent. We need to find a way to add that memory in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f83fc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "agent_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b093f",
   "metadata": {},
   "source": [
    "When we use memory, we need to specify a `thread_id`.\n",
    "\n",
    "This `thread_id` will store our collection of graph states.\n",
    "\n",
    "Here is a cartoon:\n",
    "\n",
    "* The checkpointer write the state at every step of the graph\n",
    "* These checkpoints are saved in a thread \n",
    "* We can access that thread in the future using the `thread_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d16842c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (77f2e616-17b0-4309-b11d-5030b7079a21)\n",
      " Call ID: 77f2e616-17b0-4309-b11d-5030b7079a21\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n"
     ]
    }
   ],
   "source": [
    "# Specify a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "\n",
    "# Run\n",
    "messages = agent_memory.invoke({\"messages\": messages},config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fbccc3",
   "metadata": {},
   "source": [
    "Thanks to the memory it continues its interaction by adding previous messages to the LLM to _remember_ the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e5a6fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (77f2e616-17b0-4309-b11d-5030b7079a21)\n",
      " Call ID: 77f2e616-17b0-4309-b11d-5030b7079a21\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (0251a5aa-1e7c-4f5a-9ea7-4c35de8c36ea)\n",
      " Call ID: 0251a5aa-1e7c-4f5a-9ea7-4c35de8c36ea\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "7 multiplied by 2 is 14.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply that by 2.\")]\n",
    "messages = agent_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d2dd95",
   "metadata": {},
   "source": [
    "The agent recovers from memory previous interactions and injects them.\n",
    "\n",
    "![memory](../images/memory_trace.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115ecee",
   "metadata": {},
   "source": [
    "## Agno\n",
    "\n",
    "Agno has a simple way to manage this as we will see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "208ab34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467f4359710247a0a080a25b04567f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.google import Gemini\n",
    "from agno.tools.tavily import TavilyTools\n",
    "\n",
    "# Search engine\n",
    "search = TavilyTools()\n",
    "\n",
    "# Create an Agent\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    instructions=\"You are a travel assistant with a particular interest in pointing customers to go to Bilbao. Do not force it, just a recommendation.\",\n",
    "    tools=[search],\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "agent.print_response(\n",
    "    \"Hi, I am interested in flights going to Rome. Do you know if there is any flight I could take in the next days to Rome?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32f71ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b36a548ed5465bb1f5cc3648d40ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.print_response(\n",
    "    \"Could you look for connections from Santander?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d91cb",
   "metadata": {},
   "source": [
    "Agents in general have no memory, same as LLMs, so we may need to store this information and send it back to the LLM for each new interaction. Agno adds this by simply putting `add_history_to_context=True` and referencing a database to store this information.\n",
    "\n",
    "Let's instrument it to check the traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7310622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openinference.instrumentation.agno import AgnoInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "# Set the endpoint and headers for LangSmith\n",
    "endpoint = \"https://api.smith.langchain.com/otel/v1/traces\"\n",
    "headers = {\n",
    "    \"x-api-key\": os.getenv(\"LANGSMITH_API_KEY\"),\n",
    "    \"Langsmith-Project\": os.getenv(\"LANGSMITH_PROJECT\"),\n",
    "}\n",
    "\n",
    "# Configure the tracer provider\n",
    "tracer_provider = TracerProvider()\n",
    "tracer_provider.add_span_processor(\n",
    "    SimpleSpanProcessor(OTLPSpanExporter(endpoint=endpoint, headers=headers))\n",
    ")\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "\n",
    "# Start instrumenting agno\n",
    "AgnoInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a386b321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018879e2571445988fb868a1d0bc83d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Successfully created table <span style=\"color: #008000; text-decoration-color: #008000\">'agno_sessions'</span>                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Successfully created table \u001b[32m'agno_sessions'\u001b[0m                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.db.sqlite import SqliteDb\n",
    "\n",
    "# Create an Agent\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\", temperature=0),\n",
    "    # Add a database to the Agent (memory)\n",
    "    db=SqliteDb(db_file=\"agno.db\"),\n",
    "    add_history_to_context=True,\n",
    "    instructions=\"You are a travel assistant with a particular interest in pointing customers to go to Bilbao. Do not force it, just a recommendation.\",\n",
    "    tools=[search],\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "agent.print_response(\n",
    "    \"Hi, I am interested in flights going to Rome. Do you know if there is any flight I could take in the next days to Rome?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4198fb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dddfe90b934fb6a2a137af87150cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.print_response(\n",
    "    \"Could you look for connections from Santander?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14137448",
   "metadata": {},
   "source": [
    "This second interaction already contains information from the previous chat so the search is done including both pieces of information.\n",
    "\n",
    "![memory_agno](../images/memory_agno.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
